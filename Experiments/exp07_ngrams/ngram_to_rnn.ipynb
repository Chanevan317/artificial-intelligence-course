{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzkmD0vK8rId"
      },
      "source": [
        "#N-Gram to Neural to RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfgvlj4r8vOq",
        "outputId": "fe2486bf-e0b8-4d75-bb2b-fd3da82d8d8c"
      },
      "outputs": [],
      "source": [
        "%pip install nltk torch numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH5Df3nA9p73",
        "outputId": "0fac2c3d-19d4-43f6-920b-609e2c7951d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q_7Ja5RD9sog"
      },
      "outputs": [],
      "source": [
        "corpus = \"\"\"\n",
        "machine learning is a field of artificial intelligence that allows systems to learn from data\n",
        "machine learning models improve automatically through experience\n",
        "deep neural networks are a powerful type of machine learning model\n",
        "recurrent neural networks are useful for sequential data processing\n",
        "in natural language processing models need to understand long term dependencies\n",
        "to understand long term dependencies models must remember earlier words in a sentence\n",
        "if the weather is cold then wear a jacket\n",
        "if the weather is hot then wear a hat\n",
        "if there is not certainity of weather you can wear of your choice\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9dFbDfQ9wdC",
        "outputId": "b25f7955-751d-4401-8277-6a56e6a20ab2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "#N-Gram based models\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "tokens = nltk.word_tokenize(corpus.lower())\n",
        "\n",
        "vocab = sorted(set(tokens))\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4V9_TYAd928o"
      },
      "outputs": [],
      "source": [
        "bigrams = list(nltk.bigrams(tokens))\n",
        "bigram_freq = defaultdict(Counter)\n",
        "\n",
        "for w1, w2 in bigrams:\n",
        "    bigram_freq[w1][w2] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iFbGDaui99Z0"
      },
      "outputs": [],
      "source": [
        "def predict_ngram(word):\n",
        "    if word in bigram_freq:\n",
        "        return bigram_freq[word].most_common(1)[0][0]\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJvYb-am9_I4",
        "outputId": "986c6bc6-752f-44e9-d167-e27ff5d46a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-Gram Prediction: learning\n"
          ]
        }
      ],
      "source": [
        "print(\"N-Gram Prediction:\", predict_ngram(\"machine\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5dAoUpS_O8J",
        "outputId": "4d676be7-d33b-44ad-d455-6984402026cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-Gram Accuracy: 0.7604166666666666\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for w1, w2 in bigrams:\n",
        "    if predict_ngram(w1) == w2:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "ngram_accuracy = correct / total\n",
        "print(\"N-Gram Accuracy:\", ngram_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VqEdDdoN-BH_"
      },
      "outputs": [],
      "source": [
        "#Feed Forward Neural Network (NN)\n",
        "context_size = 2\n",
        "data = []\n",
        "\n",
        "for i in range(len(tokens) - context_size):\n",
        "    context = tokens[i:i+context_size]\n",
        "    target = tokens[i+context_size]\n",
        "    data.append((context, target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CTSVe0yl-MuG"
      },
      "outputs": [],
      "source": [
        "#Convert to indices:\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for context, target in data:\n",
        "    X.append([word_to_ix[w] for w in context])\n",
        "    y.append(word_to_ix[target])\n",
        "\n",
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GgaWyh87-OuP"
      },
      "outputs": [],
      "source": [
        "#Neural network defining\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, context_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc1 = nn.Linear(context_size * embed_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x).view(x.shape[0], -1)\n",
        "        out = torch.relu(self.fc1(embeds))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjaMSU4X-Ugo",
        "outputId": "29456de1-5bde-4b9d-c760-3a25f2c98ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN Training Loss: 0.0933239683508873\n"
          ]
        }
      ],
      "source": [
        "#Model training\n",
        "model_nn = FeedForwardNN(len(vocab), 50, context_size)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_nn.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    output = model_nn(X)\n",
        "    loss = loss_fn(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"NN Training Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUbdcrPY-WlQ",
        "outputId": "9f3478cf-edb7-4418-8c67-760dc017897a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feed Forward NN Accuracy: 0.9368421052631579\n"
          ]
        }
      ],
      "source": [
        "#prediction\n",
        "with torch.no_grad():\n",
        "    output = model_nn(X)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    nn_accuracy = accuracy_score(y.numpy(), preds.numpy())\n",
        "\n",
        "print(\"Feed Forward NN Accuracy:\", nn_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "atk7SxuHAIlO"
      },
      "outputs": [],
      "source": [
        "def predict_nn(context_words):\n",
        "    indices = torch.tensor([[word_to_ix[w] for w in context_words]])\n",
        "    output = model_nn(indices)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    return ix_to_word[pred.item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qWAo9kdu-YSN"
      },
      "outputs": [],
      "source": [
        "##RNN Model: prepare sequential data\n",
        "sequence_length = 3\n",
        "sequences = []\n",
        "\n",
        "for i in range(len(tokens) - sequence_length):\n",
        "    seq = tokens[i:i+sequence_length]\n",
        "    target = tokens[i+sequence_length]\n",
        "    sequences.append((seq, target))\n",
        "\n",
        "X_rnn = torch.tensor([[word_to_ix[w] for w in seq] for seq, _ in sequences])\n",
        "y_rnn = torch.tensor([word_to_ix[target] for _, target in sequences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ogHBiDI3-bmZ"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        out, hidden = self.rnn(embeds)\n",
        "        out = self.fc(out[:, -1, :])  # last timestep\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZmbK39f-9ab",
        "outputId": "36cf10c1-a6cf-4b93-9223-5be57363dabf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN Final Loss: 0.0590660385787487\n"
          ]
        }
      ],
      "source": [
        "#Train RNN model\n",
        "model_rnn = RNNModel(len(vocab), 50, 128)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_rnn.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(150):\n",
        "    optimizer.zero_grad()\n",
        "    output = model_rnn(X_rnn)\n",
        "    loss = loss_fn(output, y_rnn)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"RNN Final Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Sl1kxx_Aw5",
        "outputId": "26de96f5-1d54-4379-b892-cd8d2b293000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vanilla RNN Accuracy: 0.9574468085106383\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "with torch.no_grad():\n",
        "    output = model_rnn(X_rnn)\n",
        "    _, preds = torch.max(output, 1)\n",
        "    rnn_accuracy = accuracy_score(y_rnn.numpy(), preds.numpy())\n",
        "\n",
        "print(\"Vanilla RNN Accuracy:\", rnn_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fQ8RH-k-AB2-"
      },
      "outputs": [],
      "source": [
        "def predict_rnn(context_words):\n",
        "    indices = torch.tensor([[word_to_ix[w] for w in context_words]])\n",
        "    output = model_rnn(indices)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    return ix_to_word[pred.item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DsqUzWO_DxD",
        "outputId": "c929a668-07e9-47c5-ce6e-4366fe362c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Comparison:\n",
            "------------------\n",
            "N-Gram Accuracy      : 0.7604166666666666\n",
            "FeedForward Accuracy : 0.9368421052631579\n",
            "Vanilla RNN Accuracy : 0.9574468085106383\n"
          ]
        }
      ],
      "source": [
        "#comparison\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(\"------------------\")\n",
        "print(\"N-Gram Accuracy      :\", ngram_accuracy)\n",
        "print(\"FeedForward Accuracy :\", nn_accuracy)\n",
        "print(\"Vanilla RNN Accuracy :\", rnn_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "R5fKZf3F_HLw"
      },
      "outputs": [],
      "source": [
        "#prediction of words\n",
        "test_sentence = \"deep neural networks allows machine learning\"\n",
        "test_tokens = nltk.word_tokenize(test_sentence.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oxUMVzh_x_l",
        "outputId": "b5172596-40b7-4ad0-f090-21b4b3549e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N-Gram Prediction: is\n",
            "FeedForward Prediction: models\n",
            "RNN Prediction: model\n"
          ]
        }
      ],
      "source": [
        "print(\"N-Gram Prediction:\", predict_ngram(test_tokens[-1]))\n",
        "print(\"FeedForward Prediction:\", predict_nn(test_tokens[-2:]))\n",
        "print(\"RNN Prediction:\", predict_rnn(test_tokens[-5:]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
